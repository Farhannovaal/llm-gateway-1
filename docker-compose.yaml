services:
  llm-gateway:
    build: .
    ports: ["3000:3000"]
    env_file: [.env]
    restart: unless-stopped
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: ollama
  #   ports: ["11434:11434"]
  #   volumes: ["./.ollama:/root/.ollama"]
  #   restart: unless-stopped

# Provider (gratis/open-source default = ollama)
LLM_PROVIDER=ollama
MODEL_ID=qwen2.5:7b-instruct
OLLAMA_BASE_URL=http://localhost:11434

# OpenAI (opsional)
OPENAI_API_KEY=

# Inter-service security
HMAC_SHARED_SECRET=supersecret

# Server
PORT=3000
RATE_LIMIT_PER_MIN=60
